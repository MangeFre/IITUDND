{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import csv\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tweepy\n",
    "# We must use the API to determine whether the tweets are protected\n",
    "from tweepy import TweepError\n",
    "import numpy as np\n",
    "from utilities import data_handler\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "UNLABELED_DATA = '/Users/ianmagnusson/IITUDND/data/retrieved_data/harvey_extras.json'\n",
    "LABELED_DATA = '/Users/ianmagnusson/IITUDND/data/CrisisMMD_v1.0/json/hurricane_harvey_final_data.json'\n",
    "CLASSIFICATIONS = '/Users/ianmagnusson/IITUDND/data/CrisisMMD_v1.0/annotations/hurricane_harvey_final_data.tsv'\n",
    "NPY_OUTFILE = '/Users/ianmagnusson/IITUDND/data/extracted_features/TFIDF/harvey/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def construct_vectorizer(merged):\n",
    "    allTweets = []\n",
    "    for i, tweet_json in enumerate(merged):\n",
    "        text = tweet_json['text'].lower()\n",
    "        allTweets.append(text)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(allTweets)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_histories(histories, vectorizer):\n",
    "    rawHistories = [] # Will be in order\n",
    "    for i, history in enumerate(histories):\n",
    "        text = ' '.join([tweet_json['text'].lower() for tweet_json in history])\n",
    "        rawHistories.append(text)\n",
    "    histArr = vectorizer.transform(rawHistories)\n",
    "    historySVD = TruncatedSVD(n_components=200, n_iter=7, random_state=42)\n",
    "    histFeatureArr = historySVD.fit_transform(histArr)\n",
    "    histFeatureArr = np.array(histFeatureArr)\n",
    "    return histFeatureArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_tweets(tweets, vectorizer):\n",
    "    labeledTweets = []  # Will be in order\n",
    "    for i, tweet_json in enumerate(tweets):\n",
    "        text = tweet_json['text'].lower()\n",
    "        labeledTweets.append(text)\n",
    "    tweetArr = vectorizer.transform(labeledTweets)\n",
    "    tweetSVD = TruncatedSVD(n_components=200, n_iter=7, random_state=42)\n",
    "    tweetFeatureArr = tweetSVD.fit_transform(tweetArr)\n",
    "    tweetFeatureArr = np.array(tweetFeatureArr)\n",
    "    return tweetFeatureArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "datahandler = data_handler.DataHandler(UNLABELED_DATA, LABELED_DATA, CLASSIFICATIONS)\n",
    "train_labeled, train_histories, test_labeled, test_histories, merged, trainClassifications, \\\n",
    "testClassifications = datahandler.get_train_test_split()\n",
    "\n",
    "vectorizer = construct_vectorizer(merged)\n",
    "trainHistories = vectorize_histories(train_histories, vectorizer)\n",
    "trainTweets = vectorize_tweets(train_labeled, vectorizer)\n",
    "testHistories = vectorize_histories(test_histories, vectorizer)\n",
    "testTweets = vectorize_tweets(test_labeled, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Add classifications to the end of labeled train and test tweet ndarrays\n",
    "trainClassifications = np.array(trainClassifications)\n",
    "testClassifications = np.array(testClassifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Shape of train history np array: (3200, 200)\nShape of train tweets np array): (3200, 200)\nShape of test history np array: (800, 200)\nShape of test tweets np array: (800, 200)\nShape of train classifications: (3200,)\nShape of test classifications: (800,)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Validation checks\n",
    "print(\"Shape of train history np array:\", trainHistories.shape)\n",
    "print(\"Shape of train tweets np array):\", trainTweets.shape)\n",
    "print(\"Shape of test history np array:\", testHistories.shape)\n",
    "print(\"Shape of test tweets np array:\", testTweets.shape)\n",
    "print(\"Shape of train classifications:\", trainClassifications.shape)\n",
    "print(\"Shape of test classifications:\", testClassifications.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Save to outfiles\n",
    "np.save(NPY_OUTFILE + 'trainHistories.npy', trainHistories)\n",
    "np.save(NPY_OUTFILE + 'trainTweets.npy', trainTweets)\n",
    "np.save(NPY_OUTFILE + 'testHistories.npy', testHistories)\n",
    "np.save(NPY_OUTFILE + 'testTweets.npy', testTweets)\n",
    "np.save(NPY_OUTFILE + 'trainClassifications.npy', trainClassifications)\n",
    "np.save(NPY_OUTFILE + 'testClassifications.npy', testClassifications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}