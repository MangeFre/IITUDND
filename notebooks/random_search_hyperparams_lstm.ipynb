{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from models import lstm\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# FILES TO CHANGE (This is where your sequence_nlp_harvey.zip etc is) test\n",
    "\n",
    "NPY_INPUT_DIR = '/Users/ianmagnusson/IITUDND/data/extracted_features/combined_NLP/harvey/kfold/'\n",
    "\n",
    "OUT_FILE = '/Users/ianmagnusson/IITUDND/notebooks/harvey_random_LSTM_results.npy'\n",
    "\n",
    "NUM_EXPERIMENTS = 10000000000000000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def run_experiment(input_dim, hidden_dim, num_layers, bidirectional,  learning_rate, momentum, decay_factor, epochs, data_dir):\n",
    "    \n",
    "    # load data from files\n",
    "    \n",
    "    X_seq_tfidf_train = np.load(data_dir + 'X_seq_tfidf_train.npz')\n",
    "    X_seq_tfidf_test = np.load(data_dir + 'X_seq_tfidf_test.npz')\n",
    "    \n",
    "    \n",
    "    X_seq_glove_train = np.load(data_dir + 'X_seq_glove_train.npz')\n",
    "    X_seq_glove_test = np.load(data_dir + 'X_seq_glove_test.npz')\n",
    "    \n",
    "    y_train = torch.Tensor(np.load(data_dir + 'y_train.npy'))\n",
    "    y_test = torch.Tensor(np.load(data_dir + 'y_test.npy'))\n",
    "    \n",
    "    # build lists with features concatenated\n",
    "    \n",
    "    X_raw_train = []\n",
    "    for i in range(len(y_train)):\n",
    "        file = X_seq_tfidf_train.files[i]\n",
    "        X_raw_train.append(np.concatenate((X_seq_tfidf_train[file], X_seq_glove_train[file]), axis=1))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_fit_train = np.concatenate(X_raw_train)\n",
    "    scaler.fit(X_fit_train)\n",
    "    \n",
    "    X_train = [torch.Tensor(scaler.transform(X_i)) for X_i in X_raw_train]\n",
    "    \n",
    "    X_test = []\n",
    "    for i in range(len(y_test)):\n",
    "        file = X_seq_tfidf_test.files[i]\n",
    "        X_test.append(torch.Tensor(scaler.transform(np.concatenate((X_seq_tfidf_test[file], X_seq_glove_test[file]), axis=1))))\n",
    "\n",
    "    \n",
    "    # build and train model\n",
    "    model = lstm.LSTM(input_dim=input_dim, hidden_dim=hidden_dim, num_layers = num_layers, bidirectional = bidirectional,\n",
    "                      learning_rate=learning_rate, momentum = momentum, decay_factor = decay_factor)\n",
    "    \n",
    "    model.learn(X_train, y_train, epochs = epochs)\n",
    "    \n",
    "    # evaluate\n",
    "    return model.get_accuracy(X_test, y_test)\n",
    "\n",
    "def cross_validate(input_dim, hidden_dim, num_layers, bidirectional,  learning_rate, momentum, decay_factor, epochs,\n",
    "                   data_dir, folds = 10):\n",
    "    accuracy_sum = 0.0\n",
    "    x = 0\n",
    "    for i in range(folds):\n",
    "        fold_dir = data_dir + str(i) + '/'\n",
    "        print('running fold', i)\n",
    "        acc = run_experiment(input_dim, hidden_dim, num_layers, bidirectional,\n",
    "                             learning_rate, momentum, decay_factor,epochs,fold_dir)\n",
    "        print('fold result', acc)\n",
    "        accuracy_sum += acc\n",
    "        \n",
    "    return accuracy_sum / folds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_random_params(range_hd, range_nl, range_lr, range_mo, range_dr, range_ep):\n",
    "    hidden_dim = random.randint(*range_hd)\n",
    "    num_layers = random.randint(*range_nl)\n",
    "    bidirectional = bool(random.getrandbits(1))\n",
    "    learning_rate = random.uniform(*range_lr)\n",
    "    momentum = random.uniform(*range_mo)\n",
    "    decay_factor = random.uniform(*range_dr)\n",
    "    epochs = random.randint(*range_ep)\n",
    "    \n",
    "    return hidden_dim, num_layers, bidirectional,  learning_rate, momentum, decay_factor, epochs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "starting test 0 params: (79, 2, False, 0.0385085281812448, 0.3285518012817997, 0.41850346994733556, 1)\n",
      "running fold 0\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.853125\n",
      "running fold 1\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.834375\n",
      "running fold 2\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.809375\n",
      "running fold 3\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.85\n",
      "running fold 4\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.821875\n",
      "running fold 5\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.809375\n",
      "running fold 6\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.846875\n",
      "running fold 7\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.834375\n",
      "running fold 8\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.85625\n",
      "running fold 9\n",
      "epoch: 0 learning rate: [0.0385085281812448]\n",
      "fold result 0.875\n",
      "test outcome 0.8390625\n",
      "************************************************************\n",
      "top so far\n",
      "[(0.8390625, (79, 2, False, 0.0385085281812448, 0.3285518012817997, 0.41850346994733556, 1))]\n",
      "************************************************************\n",
      "starting test 1 params: (229, 1, False, 0.06458222084801282, 0.10133777879777406, 0.5428415073289721, 1)\n",
      "running fold 0\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.85625\n",
      "running fold 1\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.81875\n",
      "running fold 2\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.80625\n",
      "running fold 3\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.85625\n",
      "running fold 4\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.815625\n",
      "running fold 5\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.815625\n",
      "running fold 6\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.846875\n",
      "running fold 7\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.8375\n",
      "running fold 8\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.859375\n",
      "running fold 9\n",
      "epoch: 0 learning rate: [0.06458222084801282]\n",
      "fold result 0.85625\n",
      "test outcome 0.8368749999999998\n",
      "************************************************************\n",
      "top so far\n",
      "[(0.8390625, (79, 2, False, 0.0385085281812448, 0.3285518012817997, 0.41850346994733556, 1))]\n",
      "************************************************************\n",
      "starting test 2 params: (320, 1, False, 0.08762811941340864, 0.48741215472601684, 0.24006736049430696, 3)\n",
      "running fold 0\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.85\n",
      "running fold 1\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.840625\n",
      "running fold 2\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.846875\n",
      "running fold 3\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.834375\n",
      "running fold 4\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.81875\n",
      "running fold 5\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.81875\n",
      "running fold 6\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.85625\n",
      "running fold 7\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.815625\n",
      "running fold 8\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.85625\n",
      "running fold 9\n",
      "epoch: 0 learning rate: [0.08762811941340864]\n",
      "epoch: 1 learning rate: [0.02103665133265695]\n",
      "epoch: 2 learning rate: [0.005050213359069999]\n",
      "fold result 0.846875\n",
      "test outcome 0.8384375000000001\n",
      "************************************************************\n",
      "top so far\n",
      "[(0.8390625, (79, 2, False, 0.0385085281812448, 0.3285518012817997, 0.41850346994733556, 1))]\n",
      "************************************************************\n",
      "starting test 3 params: (165, 2, False, 0.06260648419485565, 0.3644956978286912, 0.9029740472433256, 3)\n",
      "running fold 0\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.84375\n",
      "running fold 1\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.8375\n",
      "running fold 2\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.815625\n",
      "running fold 3\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.815625\n",
      "running fold 4\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.778125\n",
      "running fold 5\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.790625\n",
      "running fold 6\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.83125\n",
      "running fold 7\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.8\n",
      "running fold 8\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.8375\n",
      "running fold 9\n",
      "epoch: 0 learning rate: [0.06260648419485565]\n",
      "epoch: 1 learning rate: [0.056532030417104105]\n",
      "epoch: 2 learning rate: [0.05104695630461528]\n",
      "fold result 0.8\n",
      "test outcome 0.8150000000000001\n",
      "************************************************************\n",
      "top so far\n",
      "[(0.8390625, (79, 2, False, 0.0385085281812448, 0.3285518012817997, 0.41850346994733556, 1))]\n",
      "************************************************************\n",
      "starting test 4 params: (105, 2, True, 0.016148189613284666, 0.16183430060650705, 0.4183639993696062, 4)\n",
      "running fold 0\n",
      "epoch: 0 learning rate: [0.016148189613284666]\n",
      "epoch: 1 learning rate: [0.0067558211891925075]\n",
      "epoch: 2 learning rate: [0.0028263923717365066]\n",
      "epoch: 3 learning rate: [0.0011824608164274317]\n",
      "fold result 0.853125\n",
      "running fold 1\n",
      "epoch: 0 learning rate: [0.016148189613284666]\n",
      "epoch: 1 learning rate: [0.0067558211891925075]\n",
      "epoch: 2 learning rate: [0.0028263923717365066]\n",
      "epoch: 3 learning rate: [0.0011824608164274317]\n",
      "fold result 0.834375\n",
      "running fold 2\n",
      "epoch: 0 learning rate: [0.016148189613284666]\n",
      "epoch: 1 learning rate: [0.0067558211891925075]\n",
      "epoch: 2 learning rate: [0.0028263923717365066]\n",
      "epoch: 3 learning rate: [0.0011824608164274317]\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8fb1d98afd64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#hyperparams = get_random_params(range_hd, range_nl, range_lr, range_mo, range_dr, range_ep)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starting test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'params:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNPY_INPUT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test outcome'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'************************************************************'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8b4ac6eab737>\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(input_dim, hidden_dim, num_layers, bidirectional, learning_rate, momentum, decay_factor, epochs, data_dir, folds)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'running fold'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         acc = run_experiment(input_dim, hidden_dim, num_layers, bidirectional,\n\u001b[0;32m---> 51\u001b[0;31m                              learning_rate, momentum, decay_factor,epochs,fold_dir)\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fold result'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0maccuracy_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8b4ac6eab737>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(input_dim, hidden_dim, num_layers, bidirectional, learning_rate, momentum, decay_factor, epochs, data_dir)\u001b[0m\n\u001b[1;32m     36\u001b[0m                       learning_rate=learning_rate, momentum = momentum, decay_factor = decay_factor)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IITUDND/models/lstm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# send to gpu if available (X_i are sent later)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'learning rate:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;31m#running_loss = 0.0 # this variable just for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/IITUDND/models/lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X_i)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \"\"\"\n\u001b[1;32m     54\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0mto\u001b[0m \u001b[0mclassify\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mX_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0md\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0msingle\u001b[0m \u001b[0muser\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0md\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minformative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "range_hd = (50,500)\n",
    "range_nl = (1, 2)\n",
    "range_lr = (.1, .0001)\n",
    "range_mo = (0,1)\n",
    "range_dr = (.1,1)\n",
    "range_ep = (1,4)\n",
    "\n",
    "param_list =[]\n",
    "for i in range(1000):\n",
    "    param_list.append(get_random_params(range_hd, range_nl, range_lr, range_mo, range_dr, range_ep))\n",
    "\n",
    "# run this instead for first time\n",
    "#results = []\n",
    "\n",
    "# cross validate search for hyper-parameters\n",
    "with open(OUT_FILE, 'rb') as fin:\n",
    "    results = pickle.load(fin)\n",
    "    \n",
    "for i, hyperparams in enumerate(param_list):\n",
    "    #hyperparams = get_random_params(range_hd, range_nl, range_lr, range_mo, range_dr, range_ep)\n",
    "    print('starting test', i,'params:', hyperparams)\n",
    "    mean_acc = cross_validate(400, *hyperparams, NPY_INPUT_DIR)\n",
    "    print('test outcome', mean_acc)\n",
    "    print('************************************************************')\n",
    "    results.append((mean_acc, hyperparams))\n",
    "    results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "    print('top so far')\n",
    "    print(results[:1])\n",
    "    print('************************************************************')\n",
    "    \n",
    "    # backup results\n",
    "    with open(OUT_FILE, 'wb') as fout:\n",
    "        pickle.dump(results, fout)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(results[:3])\n",
    "\n",
    "\n",
    "# RUN THIS CELL AFTER YOU HAVE INTERUPTED OR FINISHED A SEARCH TO UPDATE!!!!!!\n",
    "\n",
    "with open(OUT_FILE, 'wb') as fout:\n",
    "    pickle.dump(results, fout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}