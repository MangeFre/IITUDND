{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "from tweepy import TweepError\n",
    "from requests.exceptions import Timeout, ConnectionError\n",
    "import os\n",
    "import tweepy\n",
    "import json\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# THE CELL BELOW CONTAINS THE FILENAME CONSTANTS THAT NEED TO BE CHANGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    SOME QUICK HOW TO!\n",
    "    \n",
    "    To make this work, make sure you:\n",
    "        - Have created an output folder - python won't do it if you haven't.\n",
    "        - Have a lot of space and time, because this will probably take a long, long time.\n",
    "        - Maybe have some kind of check for what happens after 15 minutes of pulling data,\n",
    "            I have not tested it for that limit.\n",
    "'''\n",
    "\n",
    "# This file should be the one with the tweets as jsons in it.\n",
    "TWEET_ID_FILE = \"C:/Users/mfren/Desktop/maria_extras.json\"\n",
    "\n",
    "# The downloaded images should go into a folder.\n",
    "OUTPUT_DIR = \"C:/Users/mfren/Desktop/maria_images/\"\n",
    "retry_group = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(path):\n",
    "  r = requests.head(path)\n",
    "  return r.status_code == requests.codes.ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(TWEET_ID_FILE) as f:\n",
    "    all_content_as_string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the file into a list of strings.\n",
    "list_of_dicts = all_content_as_string.splitlines()\n",
    "\n",
    "# turn each string into a json object\n",
    "list_of_jsons = [json.loads(string) for string in list_of_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tweet number  0\n",
      "Finished tweet number  500\n",
      "Finished tweet number  1000\n",
      "Finished tweet number  1500\n",
      "Finished tweet number  2000\n",
      "Finished tweet number  2500\n",
      "Finished tweet number  3000\n",
      "Finished tweet number  3500\n",
      "Finished tweet number  4000\n",
      "Finished tweet number  4500\n",
      "Finished tweet number  5000\n",
      "Finished tweet number  5500\n",
      "Finished tweet number  6000\n",
      "Finished tweet number  6500\n",
      "Finished tweet number  7000\n",
      "Finished tweet number  7500\n",
      "Finished tweet number  8000\n",
      "Finished tweet number  8500\n",
      "Finished tweet number  9000\n",
      "Finished tweet number  9500\n",
      "Finished tweet number  10000\n",
      "Finished tweet number  10500\n",
      "Finished tweet number  11000\n",
      "Finished tweet number  11500\n",
      "Finished tweet number  12000\n",
      "Finished tweet number  12500\n",
      "Finished tweet number  13000\n",
      "Finished tweet number  13500\n",
      "Finished tweet number  14000\n",
      "Finished tweet number  14500\n",
      "Finished tweet number  15000\n",
      "Finished tweet number  15500\n",
      "Finished tweet number  16000\n",
      "Finished tweet number  16500\n",
      "Finished tweet number  17000\n",
      "Finished tweet number  17500\n",
      "Finished tweet number  18000\n",
      "Finished tweet number  18500\n",
      "Finished tweet number  19000\n",
      "Finished tweet number  19500\n",
      "Finished tweet number  20000\n",
      "Finished tweet number  20500\n",
      "Finished tweet number  21000\n",
      "Finished tweet number  21500\n",
      "Finished tweet number  22000\n",
      "Finished tweet number  22500\n",
      "Found and downloaded 7974  images and 15083  other tweets. Total:  22619\n"
     ]
    }
   ],
   "source": [
    "# Go through the whole list of tweets and download the images.\n",
    "\n",
    "image_count = 0\n",
    "non_image_count = 0\n",
    "\n",
    "for i in range(0, len(list_of_jsons)):\n",
    "\n",
    "    # If there is media attached to the tweet.\n",
    "    if 'extended_entities' in list_of_jsons[i]:\n",
    "        # Make a temp (a little cleaner than getting it constantly)\n",
    "        currentJson = dict(list_of_jsons[i])\n",
    "\n",
    "        if len(list_of_jsons[i]['extended_entities']['media']) > 1: # Only iterate through and get the additional pics if\n",
    "            # the tweet had more than one image attached.\n",
    "\n",
    "            # Ok, iterate through each link in the media list - excluding the first one because we already have it.\n",
    "            for j in range(1, len(currentJson['extended_entities']['media'])):\n",
    "\n",
    "                # Assign the URL for the media-piece.\n",
    "                currentUrl = currentJson['extended_entities']['media'][j]['media_url_https']\n",
    "\n",
    "                # Check if the picture URL works and if the photo is indeed, a photo\n",
    "                try:\n",
    "                    if (exists(currentUrl) and currentJson['extended_entities']['media'][j]['type'] == 'photo'):\n",
    "                        # Do the raw stream magic (Who knows how this works)\n",
    "                        url_raw = requests.get(currentUrl, stream=True)\n",
    "                        url_raw.raw.decode_content = True\n",
    "\n",
    "                        # NAMING SCHEME: tweetID + userID + index of img\n",
    "                        with open(OUTPUT_DIR + str(currentJson['id']) + '_' +\n",
    "                                  str(currentJson['user']['id']) + \"_\" + str(j) + \".jpg\", 'wb+') as fin:\n",
    "                            shutil.copyfileobj(url_raw.raw, fin)\n",
    "\n",
    "                        # Remove the image url response object - because you should.\n",
    "                        del url_raw\n",
    "\n",
    "                        image_count += 1\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    retry_group.append(currentJson)\n",
    "    else:\n",
    "        non_image_count += 1\n",
    "    if (i % 500 == 0):\n",
    "        print(\"Finished tweet number \", i)\n",
    "\n",
    "\n",
    "# Repeat the same process for the retry group until the retry list is empty:\n",
    "while len(retry_group) != 0:\n",
    "    print(\"Running through the retry group now... \", len(retry_group), \" items in the retry group: \")\n",
    "\n",
    "    # If there is media attached to the tweet.\n",
    "    if 'extended_entities' in retry_group[0]:\n",
    "        # Make a temp (a little cleaner than getting it constantly)\n",
    "        currentJson = dict(retry_group[0])\n",
    "        retry_group.pop(0)  # Remove the current json from the retry list\n",
    "\n",
    "        if len(retry_group[0]['extended_entities']['media']) > 1:  # Only iterate through and get the additional pics if\n",
    "        # the tweet had more than one image attached.\n",
    "\n",
    "            # Ok, iterate through each link in the media list.\n",
    "            for j in range(1, len(currentJson['extended_entities']['media'])):\n",
    "\n",
    "                # Assign the URL for the media-piece.\n",
    "                currentUrl = currentJson['extended_entities']['media'][j]['media_url_https']\n",
    "\n",
    "                # Check if the picture URL works and if the photo is indeed, a photo\n",
    "                try:\n",
    "                    if (exists(currentUrl) and currentJson['extended_entities']['media'][j]['type'] == 'photo'):\n",
    "                        # Do the raw stream magic (Who knows how this works)\n",
    "                        url_raw = requests.get(currentUrl, stream=True)\n",
    "                        url_raw.raw.decode_content = True\n",
    "\n",
    "                        # NAMING SCHEME: tweetID + userID + index of img\n",
    "                        with open(OUTPUT_DIR + str(currentJson['id']) + '_' +\n",
    "                                  str(currentJson['user']['id']) + \"_\" + str(j) + \".jpg\", 'wb+') as fin:\n",
    "                            shutil.copyfileobj(url_raw.raw, fin)\n",
    "\n",
    "                        # Remove the image url response object - because you should.\n",
    "                        del url_raw\n",
    "\n",
    "                        image_count += 1\n",
    "                except requests.exceptions.RequestException as e:  # If another error occurs, add it back to the retry list\n",
    "                    retry_group.append(currentJson)\n",
    "        else:\n",
    "            non_image_count += 1\n",
    "\n",
    "\n",
    "# So you know once it is done, + some S T A T I S T I C S\n",
    "print(\"Found and downloaded\", image_count, \" images and\", non_image_count, \" other tweets. Total: \", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
