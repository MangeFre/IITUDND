{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# THE CELL BELLOW CONTAINS THE FILENAMES TO CHANGE\n",
    "This script follows this pytorch tutorial: https://pytorch.org/hub/pytorch_vision_resnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LABELED_DIR = '../data/CrisisMMD_v1.0/data_image/california_wildfires/'\n",
    "UNLABELED_DIR = '../data/retrieved_data/images/calfire_images_complete/'\n",
    "NPY_OUTPUT_DIR = '../data/extracted_features/resnet/calfire/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jack/.cache/torch/hub/pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "model = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)\n",
    "model.eval()\n",
    "model.fc = torch.nn.Identity() # replace the last layer with a pass thru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define image preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First get labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "399\n",
      "599\n",
      "799\n",
      "999\n",
      "1199\n",
      "1399\n"
     ]
    }
   ],
   "source": [
    "date_dirs =os.listdir(LABELED_DIR)\n",
    "\n",
    "count = 0\n",
    "features_vectors = {}\n",
    "image_sizes = {}\n",
    "\n",
    "for date_dir in date_dirs:\n",
    "    if date_dir == '.DS_Store':\n",
    "            continue\n",
    "    filepath = LABELED_DIR + date_dir\n",
    "    for filename in os.listdir(filepath):\n",
    "        if filename == '.DS_Store':\n",
    "            continue\n",
    "        input_image = Image.open(filepath +'/' +filename)\n",
    "        image_sizes[filename] = input_image.size\n",
    "        \n",
    "        # remove alpha channel if transperency \n",
    "        # https://stackoverflow.com/questions/9166400/convert-rgba-png-to-rgb-with-pil\n",
    "        if input_image.mode == 'RGBA':\n",
    "            input_image = Image.fromarray(np.array(input_image)[:,:,:3], 'RGB')\n",
    "            \n",
    "        # handle palleted images NOTE THIS WILL STILL RAISE WARNINGS but we are just removing the alpha channel\n",
    "        # https://stackoverflow.com/questions/52307290/what-is-the-difference-between-images-in-p-and-l-mode-in-pil\n",
    "        # also handle black and white images 'L'\n",
    "        elif input_image.mode == 'P' or input_image.mode == 'L':\n",
    "            input_image = input_image.convert('RGB')\n",
    "        \n",
    "        # handle palleted images NOTE THIS WILL STILL RAISE WARNINGS but we are just removing the alpha channel\n",
    "        # https://stackoverflow.com/questions/52307290/what-is-the-difference-between-images-in-p-and-l-mode-in-pil\n",
    "        elif input_image.mode == 'P':\n",
    "            input_image = input_image.convert('RGB')\n",
    "        \n",
    "        input_tensor = preprocess(input_image)\n",
    "            \n",
    "        input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    \n",
    "        # move the input and model to GPU for speed if available\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = input_batch.to('cuda')\n",
    "            model.to('cuda')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features_vectors[filename] = model(input_batch)[0].cpu().numpy()\n",
    "        \n",
    "        count += 1\n",
    "        if count % 200 == 199:\n",
    "            print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a dictionary {filename : np.array}\n",
    "\n",
    "with open(NPY_OUTPUT_DIR + 'labeled.npz', 'wb+') as fout:\n",
    "    np.savez_compressed(fout, **features_vectors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(NPY_OUTPUT_DIR + 'image_sizes_labeled.p', 'wb') as fout:\n",
    "    pickle.dump(image_sizes, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load example\n",
    "#with open(NPY_OUTPUT_DIR + 'image_sizes.p', 'rb') as fin:\n",
    "    #image_sizes = pickle.load(fin)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Next get unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/anaconda3/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "399\n",
      "599\n",
      "799\n",
      "999\n",
      "1199\n",
      "1399\n",
      "1599\n",
      "1799\n",
      "1999\n",
      "2199\n",
      "2399\n",
      "2599\n",
      "2799\n",
      "2999\n",
      "3199\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "features_vectors = {}\n",
    "image_sizes = {}\n",
    "\n",
    "for filename in os.listdir(UNLABELED_DIR):\n",
    "    if filename == '.DS_Store':\n",
    "        continue\n",
    "    input_image = Image.open(UNLABELED_DIR + filename)\n",
    "    image_sizes[filename] = input_image.size\n",
    "    \n",
    "    # remove alpha channel if transperency \n",
    "    # https://stackoverflow.com/questions/9166400/convert-rgba-png-to-rgb-with-pil\n",
    "    if input_image.mode == 'RGBA':\n",
    "        input_image = Image.fromarray(np.array(input_image)[:,:,:3], 'RGB') \n",
    "        \n",
    "    # handle palleted images NOTE THIS WILL STILL RAISE WARNINGS but we are just removing the alpha channel\n",
    "    # https://stackoverflow.com/questions/52307290/what-is-the-difference-between-images-in-p-and-l-mode-in-pil\n",
    "    # also handle black and white images 'L'\n",
    "    elif input_image.mode == 'P' or input_image.mode == 'L':\n",
    "       input_image = input_image.convert('RGB')\n",
    "    \n",
    "    input_tensor = preprocess(input_image)\n",
    "        \n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features_vectors[filename] = model(input_batch)[0].cpu().numpy()\n",
    "    \n",
    "    count += 1\n",
    "    if count % 200 == 199:\n",
    "        print(count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save as a dictionary {filename : np.array}\n",
    "\n",
    "with open(NPY_OUTPUT_DIR + 'unlabeled.npz', 'wb+') as fout:\n",
    "    np.savez_compressed(fout, **features_vectors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(NPY_OUTPUT_DIR + 'image_sizes_unlabeled.p', 'wb') as fout:\n",
    "    pickle.dump(image_sizes, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
